{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST DATASET\n",
    "\n",
    "This note book will explain what the mnist dataset is and how to read the data into memory so it can be used to train a nural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [What is the Mnist Dataset](#WhatIs)\n",
    "2. [Imports](#Imports)\n",
    "3. [Reading bytes from file](#reading)\n",
    "4. [Little and Big Endian](#endian)\n",
    "5. [Displaying the Image](#image)\n",
    "6. [Displaying the Labels](#label)\n",
    "7. [Conclusion](#conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Mnist Dataset <a name=\"WhatIs\"></a>\n",
    "\n",
    "The MNIST dataset is a very large database of handwritten digits that is commonly used for training various image processing systems. The dataset is also widely used in the field of machine learning. \n",
    "\n",
    "This dataset itself is presented in four files.\n",
    "The first file contains 60,000 training images.\n",
    "The second file contains 60,000 labels for the training images.\n",
    "The Third file contains 10,000 test images.\n",
    "The fourth file contians 10,000 labels for the test images.\n",
    "\n",
    "The files can be located and downloaded from the MNIST website in gzip form. The images are not in any standard image rendering format, therefore we must write our own program to be able to read the images and save them in the .png format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports <a name=\"Imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Bytes From Files <a name=\"reading\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    file_content = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Little and Big Endian <a name=\"endian\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bytes can be read differently depending on which cpu you are using.\n",
    "\n",
    "Big endian treats the farthest binary value to the left as the most significant value.\n",
    "\n",
    "Little endian treats the farthest binary value to the right as the most significant value.\n",
    "\n",
    " First, we get the first four bytes as a slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = file_content[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now get the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the magic number. This value should be 2051 if the data has been read correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2051"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(file_content[0:4], byteorder='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next reserved four bytes are the amount of images the file contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_content[4:8]\n",
    "\n",
    "int.from_bytes(file_content[4:8], byteorder='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there is 60000 images in the above example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next eight bytes contain the dimensions of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_content[8:12]\n",
    "int.from_bytes(file_content[8:12], byteorder='big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(file_content[12:16], byteorder='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see they are 28 x 28 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this we are reading pixel values as unsigned bytes and as the the dimensions of each image are 28 x 28 for every 784 bytes we should get a new image.\n",
    "Each unsigned byte is between 0 and 255, 0 being a value of white and 255 black.\n",
    "The pixel values between zero and 255 are darker shades of grey acending."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIsplaying the image <a name=\"image\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the image we have to create an array of the next 784 bytes in the file and set it to a 2D array of unsigned bytes using reshape.\n",
    "\n",
    "We use matplotlib to render the image in greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22190e78668>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = ~np.array(list(file_content[16:800])).reshape(28,28).astype(np.uint8)\n",
    "\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the Labels <a name=\"label\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the image labels we do the same as above but we are only getting a single integer value back.\n",
    "\n",
    "The files first 8 bytes are reserved for the magic number and amount of labels contained within the file.\n",
    "\n",
    "After the first eight bytes each subsequent byte holds the label for the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we get the first label from the file. If this matches the number displayed above we can see the files read in correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(labels [8:9], byteorder='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion <a name=\"conclusion\"></a>\n",
    "\n",
    "In this notebook I have explained what the Mnist dataset is and how you read the gzipped files into memory so that the images and labels may be used to train a nural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
